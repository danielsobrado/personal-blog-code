{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pandas import Series\n",
    "from numpy.random import randn\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "import matplotlib.pyplot as plt # for vizualization\n",
    "from matplotlib.pyplot import figure # for figuresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\daniel\\Documents\\GitHub\\datasets\\titanic\\train.csv\")\n",
    "test =  pd.read_csv(r\"C:\\Users\\daniel\\Documents\\GitHub\\datasets\\titanic\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train[\"Sex\"] = le.fit_transform(train[\"Sex\"])\n",
    "train[\"Embarked\"] = le.fit_transform(train[\"Embarked\"].astype(str))\n",
    "train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0            1         0       3    1  22.0      1      0   7.2500         2\n",
       "1            2         1       1    0  38.0      1      0  71.2833         0\n",
       "2            3         1       3    0  26.0      0      0   7.9250         2\n",
       "3            4         1       1    0  35.0      1      0  53.1000         2\n",
       "4            5         0       3    1  35.0      0      0   8.0500         2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0          892       3    1  34.5      0      0   7.8292         1\n",
       "1          893       3    0  47.0      1      0   7.0000         2\n",
       "2          894       2    1  62.0      0      0   9.6875         1\n",
       "3          895       3    1  27.0      0      0   8.6625         2\n",
       "4          896       3    0  22.0      1      1  12.2875         2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"Sex\"] = le.fit_transform(test[\"Sex\"])\n",
    "test[\"Embarked\"] = le.fit_transform(test[\"Embarked\"].astype(str))\n",
    "test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    # Drop unwanted features\n",
    "    # df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "    \n",
    "    # Fill missing data: Age and Fare with the mean, Embarked with most frequent value\n",
    "    df[['Age']] = df[['Age']].fillna(value=df[['Age']].mean())\n",
    "    df[['Fare']] = df[['Fare']].fillna(value=df[['Fare']].mean())\n",
    "    df[['Embarked']] = df[['Embarked']].fillna(value=df['Embarked'].value_counts().idxmax())\n",
    "    \n",
    "    # Convert categorical  features into numeric\n",
    "    # df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "      \n",
    "    # Convert Embarked to one-hot\n",
    "    enbarked_one_hot = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "    df = df.drop('Embarked', axis=1)\n",
    "    df = df.join(enbarked_one_hot)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prep_data(train)\n",
    "test = prep_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train\n",
    "y_train = train[\"Survived\"].to_frame()\n",
    "x_train.drop([\"Survived\"], axis=1, inplace=True)\n",
    "x_test = test\n",
    "y_test = pd.DataFrame(0, index=np.arange(len(x_test)), columns=[\"Survived\"])\n",
    "#y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 891)\n",
      "(1, 891)\n",
      "(8, 418)\n",
      "(1, 418)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "    \n",
    "    parameters = {\"W1\": np.random.randn(2,x_train.shape[0]) * 0.1,\n",
    "                  \"b1\": np.zeros((2,1)),\n",
    "                  \"W2\": np.random.randn(2,2) * 0.1,\n",
    "                  \"b2\": np.zeros((2,1)),\n",
    "                  \"W3\": np.random.randn(1,2) * 0.1,\n",
    "                  \"b3\": np.zeros((1,1))}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 11)\n",
      "(2, 2)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(parameters[\"W1\"].shape)\n",
    "print(parameters[\"W2\"].shape)\n",
    "print(parameters[\"W3\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(parameters[\"b1\"].shape)\n",
    "print(parameters[\"b2\"].shape)\n",
    "print(parameters[\"b3\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_NN(x_train, parameters):\n",
    "    \n",
    "    Z1 = np.dot(parameters[\"W1\"],x_train) + parameters[\"b1\"]\n",
    "    A1 = np.tanh(Z1) # tanh is used as activation function 1\n",
    "    Z2 = np.dot(parameters[\"W2\"],A1) + parameters[\"b2\"]\n",
    "    A2 = np.tanh(Z2) # tanh is used as activation function 2\n",
    "    Z3 = np.dot(parameters[\"W3\"],A2) + parameters[\"b3\"]\n",
    "    A3 = sigmoid(Z3)\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"W1\": parameters[\"W1\"],\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"W2\": parameters[\"W2\"],\n",
    "             \"Z3\": Z3,\n",
    "             \"A3\": A3,\n",
    "             \"W3\": parameters[\"W3\"]}\n",
    "    \n",
    "    return A3, cache\n",
    "\n",
    "A3, cache = forward_propagation_NN(x_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.02443655,  0.18282576, -0.11199662,  0.04980434, -0.09905   ,\n",
       "          0.15798178,  0.0382615 ,  0.04107357,  0.04164038, -0.00996996,\n",
       "          0.06411254],\n",
       "        [ 0.03375048, -0.05877678,  0.1074968 , -0.1951223 , -0.05563584,\n",
       "          0.11705543,  0.02206659,  0.04186943, -0.15491309,  0.00262248,\n",
       "         -0.05495038]]), 'b1': array([[0.],\n",
       "        [0.]]), 'W2': array([[-0.01268856, -0.11962667],\n",
       "        [ 0.0575027 ,  0.05200076]]), 'b2': array([[0.],\n",
       "        [0.]]), 'W3': array([[0.26442579, 0.10014938]]), 'b3': array([[0.]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50713936, 0.50717954, 0.50716459, 0.50717911, 0.50717301,\n",
       "        0.50717013, 0.50717967, 0.49904441, 0.50717445, 0.50686244,\n",
       "        0.50156461, 0.50717954, 0.50714382, 0.50717953, 0.50700297,\n",
       "        0.5071794 , 0.49753856, 0.50717308, 0.50717707, 0.50717504,\n",
       "        0.50717841, 0.50717637, 0.5070366 , 0.5071721 , 0.50351021,\n",
       "        0.50717945, 0.50717502, 0.49405817, 0.50717653, 0.5071752 ,\n",
       "        0.50717918, 0.5066219 , 0.50717678, 0.50717964, 0.50708026,\n",
       "        0.50717956, 0.50717553, 0.50711617, 0.50697701, 0.50630942,\n",
       "        0.50717908, 0.50716788, 0.50717516, 0.49430671, 0.50705789,\n",
       "        0.50717483, 0.50717556, 0.50717647, 0.5071726 , 0.50672383,\n",
       "        0.49542923, 0.50702991, 0.50717967, 0.50716576, 0.50717973,\n",
       "        0.50715148, 0.50696808, 0.50716622, 0.49445949, 0.49621245,\n",
       "        0.50698612, 0.50717129, 0.50717888, 0.49426829, 0.50714006,\n",
       "        0.5071577 , 0.50716076, 0.50627293, 0.50555098, 0.50711981,\n",
       "        0.50717002, 0.49977615, 0.50072707, 0.50705935, 0.5070979 ,\n",
       "        0.50702428, 0.50715237, 0.50715031, 0.49404932, 0.50715053,\n",
       "        0.50646755, 0.50712618, 0.50715581, 0.50660388, 0.50271241,\n",
       "        0.50716837, 0.49621689, 0.50712249, 0.4940371 , 0.50659946,\n",
       "        0.50708803, 0.50454733, 0.50717809, 0.50633311, 0.50717972,\n",
       "        0.50708201, 0.50717973, 0.49794923, 0.50713007, 0.5071265 ,\n",
       "        0.50696881, 0.50703482, 0.49501636, 0.50713206, 0.50717136,\n",
       "        0.5068175 , 0.5036055 , 0.50696483, 0.50717051, 0.50691403,\n",
       "        0.50717695, 0.4953811 , 0.50292354, 0.50104427, 0.49641882,\n",
       "        0.50108646, 0.50717973, 0.50623512, 0.49403544, 0.49403774,\n",
       "        0.49466342, 0.50663424, 0.50661776, 0.50693796, 0.50717793,\n",
       "        0.49423545, 0.50662942, 0.50235071, 0.50567764, 0.50717735,\n",
       "        0.50687743, 0.49686618, 0.50717839, 0.50472281, 0.50087884,\n",
       "        0.49772878, 0.49447539, 0.50642373, 0.4944488 , 0.49432993,\n",
       "        0.50414574, 0.49756508, 0.49889642, 0.49538531, 0.49451674,\n",
       "        0.49423222, 0.50191128, 0.49403968, 0.50626469, 0.50713654,\n",
       "        0.50717838, 0.49419369, 0.50717954, 0.50702687, 0.50348585,\n",
       "        0.50715458, 0.49426087, 0.50316403, 0.50254677, 0.49600505,\n",
       "        0.50712621, 0.50698891, 0.49737993, 0.4941534 , 0.49403491,\n",
       "        0.49403655, 0.49529586, 0.50703818, 0.49738603, 0.49470647,\n",
       "        0.50717943, 0.49403514, 0.49403495, 0.49432803, 0.5071771 ,\n",
       "        0.49410651, 0.49694372, 0.50715497, 0.49772334, 0.50566348,\n",
       "        0.49469469, 0.49656836, 0.49403537, 0.49403486, 0.49403493,\n",
       "        0.49450817, 0.49769975, 0.50683167, 0.50618236, 0.50367126,\n",
       "        0.49823733, 0.49406374, 0.49408759, 0.49403487, 0.50644446,\n",
       "        0.50654377, 0.49622074, 0.50623617, 0.49637092, 0.49418049,\n",
       "        0.4946948 , 0.49416912, 0.49870999, 0.50687151, 0.49404625,\n",
       "        0.49403487, 0.49567   , 0.49415541, 0.49404172, 0.50022071,\n",
       "        0.494117  , 0.49672481, 0.49406757, 0.49449816, 0.4948486 ,\n",
       "        0.49404329, 0.4942436 , 0.50255347, 0.49408132, 0.49438298,\n",
       "        0.49403663, 0.49412102, 0.50705343, 0.49433413, 0.49420483,\n",
       "        0.49404727, 0.4940379 , 0.49404148, 0.49403646, 0.49416241,\n",
       "        0.49409348, 0.49416999, 0.50716396, 0.49403486, 0.49404733,\n",
       "        0.49420412, 0.5010998 , 0.49403486, 0.49403621, 0.49430551,\n",
       "        0.49412741, 0.49415703, 0.49408587, 0.49403892, 0.49411382,\n",
       "        0.49466782, 0.49404775, 0.49403823, 0.49412944, 0.50665719,\n",
       "        0.49408556, 0.49406923, 0.50714205, 0.49407012, 0.49530307,\n",
       "        0.49404878, 0.49403614, 0.49403591, 0.49403485, 0.50313859,\n",
       "        0.4940695 , 0.49403485, 0.49705617, 0.49520602, 0.49406765,\n",
       "        0.49419936, 0.49403488, 0.49403767, 0.49509854, 0.49403523,\n",
       "        0.49403851, 0.49403757, 0.49450003, 0.4940747 , 0.49405157,\n",
       "        0.50638662, 0.49722132, 0.49404492, 0.49403485, 0.4940699 ,\n",
       "        0.50716024, 0.494038  , 0.49403488, 0.49403493, 0.49403662,\n",
       "        0.49404994, 0.49403941, 0.49403505, 0.4943553 , 0.49403515,\n",
       "        0.49403489, 0.49403485, 0.49405722, 0.4940352 , 0.49403513,\n",
       "        0.49403558, 0.49403504, 0.49403485, 0.49403542, 0.49403494,\n",
       "        0.49403775, 0.49403623, 0.49403489, 0.49403657, 0.49403614,\n",
       "        0.49403485, 0.49403486, 0.49403485, 0.49403535, 0.49403496,\n",
       "        0.49403486, 0.49403485, 0.49403493, 0.49403522, 0.49407605,\n",
       "        0.49403503, 0.49403489, 0.49756324, 0.49403485, 0.49403493,\n",
       "        0.49403488, 0.494035  , 0.49403539, 0.49403486, 0.49403489,\n",
       "        0.49403486, 0.50496101, 0.49403767, 0.49403512, 0.49403485,\n",
       "        0.49403509, 0.49406645, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403501, 0.49403486, 0.49403489, 0.49408534, 0.49404599,\n",
       "        0.49403485, 0.49403485, 0.49403489, 0.49403486, 0.49403557,\n",
       "        0.49403486, 0.49403857, 0.49403492, 0.49403485, 0.49404213,\n",
       "        0.49403486, 0.49403487, 0.49403485, 0.49403486, 0.49403489,\n",
       "        0.49403487, 0.49403485, 0.49403566, 0.49403491, 0.49403491,\n",
       "        0.49403515, 0.49403486, 0.49404171, 0.49403505, 0.49403488,\n",
       "        0.49403488, 0.49417265, 0.49403487, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403486, 0.49403486,\n",
       "        0.49403485, 0.49403485, 0.4940349 , 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403486, 0.49403541, 0.49403485, 0.49403485,\n",
       "        0.49403493, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49404027, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403506,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403485, 0.49403491,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403498,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49404992, 0.49403485, 0.49403496, 0.49403485,\n",
       "        0.49403487, 0.49403485, 0.49403486, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403507, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403856, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403495, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403488, 0.49403918, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403489, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 891)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50713936, 0.50717954, 0.50716459, 0.50717911, 0.50717301,\n",
       "        0.50717013, 0.50717967, 0.49904441, 0.50717445, 0.50686244,\n",
       "        0.50156461, 0.50717954, 0.50714382, 0.50717953, 0.50700297,\n",
       "        0.5071794 , 0.49753856, 0.50717308, 0.50717707, 0.50717504,\n",
       "        0.50717841, 0.50717637, 0.5070366 , 0.5071721 , 0.50351021,\n",
       "        0.50717945, 0.50717502, 0.49405817, 0.50717653, 0.5071752 ,\n",
       "        0.50717918, 0.5066219 , 0.50717678, 0.50717964, 0.50708026,\n",
       "        0.50717956, 0.50717553, 0.50711617, 0.50697701, 0.50630942,\n",
       "        0.50717908, 0.50716788, 0.50717516, 0.49430671, 0.50705789,\n",
       "        0.50717483, 0.50717556, 0.50717647, 0.5071726 , 0.50672383,\n",
       "        0.49542923, 0.50702991, 0.50717967, 0.50716576, 0.50717973,\n",
       "        0.50715148, 0.50696808, 0.50716622, 0.49445949, 0.49621245,\n",
       "        0.50698612, 0.50717129, 0.50717888, 0.49426829, 0.50714006,\n",
       "        0.5071577 , 0.50716076, 0.50627293, 0.50555098, 0.50711981,\n",
       "        0.50717002, 0.49977615, 0.50072707, 0.50705935, 0.5070979 ,\n",
       "        0.50702428, 0.50715237, 0.50715031, 0.49404932, 0.50715053,\n",
       "        0.50646755, 0.50712618, 0.50715581, 0.50660388, 0.50271241,\n",
       "        0.50716837, 0.49621689, 0.50712249, 0.4940371 , 0.50659946,\n",
       "        0.50708803, 0.50454733, 0.50717809, 0.50633311, 0.50717972,\n",
       "        0.50708201, 0.50717973, 0.49794923, 0.50713007, 0.5071265 ,\n",
       "        0.50696881, 0.50703482, 0.49501636, 0.50713206, 0.50717136,\n",
       "        0.5068175 , 0.5036055 , 0.50696483, 0.50717051, 0.50691403,\n",
       "        0.50717695, 0.4953811 , 0.50292354, 0.50104427, 0.49641882,\n",
       "        0.50108646, 0.50717973, 0.50623512, 0.49403544, 0.49403774,\n",
       "        0.49466342, 0.50663424, 0.50661776, 0.50693796, 0.50717793,\n",
       "        0.49423545, 0.50662942, 0.50235071, 0.50567764, 0.50717735,\n",
       "        0.50687743, 0.49686618, 0.50717839, 0.50472281, 0.50087884,\n",
       "        0.49772878, 0.49447539, 0.50642373, 0.4944488 , 0.49432993,\n",
       "        0.50414574, 0.49756508, 0.49889642, 0.49538531, 0.49451674,\n",
       "        0.49423222, 0.50191128, 0.49403968, 0.50626469, 0.50713654,\n",
       "        0.50717838, 0.49419369, 0.50717954, 0.50702687, 0.50348585,\n",
       "        0.50715458, 0.49426087, 0.50316403, 0.50254677, 0.49600505,\n",
       "        0.50712621, 0.50698891, 0.49737993, 0.4941534 , 0.49403491,\n",
       "        0.49403655, 0.49529586, 0.50703818, 0.49738603, 0.49470647,\n",
       "        0.50717943, 0.49403514, 0.49403495, 0.49432803, 0.5071771 ,\n",
       "        0.49410651, 0.49694372, 0.50715497, 0.49772334, 0.50566348,\n",
       "        0.49469469, 0.49656836, 0.49403537, 0.49403486, 0.49403493,\n",
       "        0.49450817, 0.49769975, 0.50683167, 0.50618236, 0.50367126,\n",
       "        0.49823733, 0.49406374, 0.49408759, 0.49403487, 0.50644446,\n",
       "        0.50654377, 0.49622074, 0.50623617, 0.49637092, 0.49418049,\n",
       "        0.4946948 , 0.49416912, 0.49870999, 0.50687151, 0.49404625,\n",
       "        0.49403487, 0.49567   , 0.49415541, 0.49404172, 0.50022071,\n",
       "        0.494117  , 0.49672481, 0.49406757, 0.49449816, 0.4948486 ,\n",
       "        0.49404329, 0.4942436 , 0.50255347, 0.49408132, 0.49438298,\n",
       "        0.49403663, 0.49412102, 0.50705343, 0.49433413, 0.49420483,\n",
       "        0.49404727, 0.4940379 , 0.49404148, 0.49403646, 0.49416241,\n",
       "        0.49409348, 0.49416999, 0.50716396, 0.49403486, 0.49404733,\n",
       "        0.49420412, 0.5010998 , 0.49403486, 0.49403621, 0.49430551,\n",
       "        0.49412741, 0.49415703, 0.49408587, 0.49403892, 0.49411382,\n",
       "        0.49466782, 0.49404775, 0.49403823, 0.49412944, 0.50665719,\n",
       "        0.49408556, 0.49406923, 0.50714205, 0.49407012, 0.49530307,\n",
       "        0.49404878, 0.49403614, 0.49403591, 0.49403485, 0.50313859,\n",
       "        0.4940695 , 0.49403485, 0.49705617, 0.49520602, 0.49406765,\n",
       "        0.49419936, 0.49403488, 0.49403767, 0.49509854, 0.49403523,\n",
       "        0.49403851, 0.49403757, 0.49450003, 0.4940747 , 0.49405157,\n",
       "        0.50638662, 0.49722132, 0.49404492, 0.49403485, 0.4940699 ,\n",
       "        0.50716024, 0.494038  , 0.49403488, 0.49403493, 0.49403662,\n",
       "        0.49404994, 0.49403941, 0.49403505, 0.4943553 , 0.49403515,\n",
       "        0.49403489, 0.49403485, 0.49405722, 0.4940352 , 0.49403513,\n",
       "        0.49403558, 0.49403504, 0.49403485, 0.49403542, 0.49403494,\n",
       "        0.49403775, 0.49403623, 0.49403489, 0.49403657, 0.49403614,\n",
       "        0.49403485, 0.49403486, 0.49403485, 0.49403535, 0.49403496,\n",
       "        0.49403486, 0.49403485, 0.49403493, 0.49403522, 0.49407605,\n",
       "        0.49403503, 0.49403489, 0.49756324, 0.49403485, 0.49403493,\n",
       "        0.49403488, 0.494035  , 0.49403539, 0.49403486, 0.49403489,\n",
       "        0.49403486, 0.50496101, 0.49403767, 0.49403512, 0.49403485,\n",
       "        0.49403509, 0.49406645, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403501, 0.49403486, 0.49403489, 0.49408534, 0.49404599,\n",
       "        0.49403485, 0.49403485, 0.49403489, 0.49403486, 0.49403557,\n",
       "        0.49403486, 0.49403857, 0.49403492, 0.49403485, 0.49404213,\n",
       "        0.49403486, 0.49403487, 0.49403485, 0.49403486, 0.49403489,\n",
       "        0.49403487, 0.49403485, 0.49403566, 0.49403491, 0.49403491,\n",
       "        0.49403515, 0.49403486, 0.49404171, 0.49403505, 0.49403488,\n",
       "        0.49403488, 0.49417265, 0.49403487, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403486, 0.49403486,\n",
       "        0.49403485, 0.49403485, 0.4940349 , 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403486, 0.49403541, 0.49403485, 0.49403485,\n",
       "        0.49403493, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49404027, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403506,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403485, 0.49403491,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403498,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49404992, 0.49403485, 0.49403496, 0.49403485,\n",
       "        0.49403487, 0.49403485, 0.49403486, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403507, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403856, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403495, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403488, 0.49403918, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403489, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_NN(A3, Y, parameters):\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A3),Y)\n",
    "    cost = -np.sum(logprobs)/Y.shape[1]\n",
    "    \n",
    "    return cost\n",
    "\n",
    "cost = compute_cost_NN(A3, y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50713936, 0.50717954, 0.50716459, 0.50717911, 0.50717301,\n",
       "        0.50717013, 0.50717967, 0.49904441, 0.50717445, 0.50686244,\n",
       "        0.50156461, 0.50717954, 0.50714382, 0.50717953, 0.50700297,\n",
       "        0.5071794 , 0.49753856, 0.50717308, 0.50717707, 0.50717504,\n",
       "        0.50717841, 0.50717637, 0.5070366 , 0.5071721 , 0.50351021,\n",
       "        0.50717945, 0.50717502, 0.49405817, 0.50717653, 0.5071752 ,\n",
       "        0.50717918, 0.5066219 , 0.50717678, 0.50717964, 0.50708026,\n",
       "        0.50717956, 0.50717553, 0.50711617, 0.50697701, 0.50630942,\n",
       "        0.50717908, 0.50716788, 0.50717516, 0.49430671, 0.50705789,\n",
       "        0.50717483, 0.50717556, 0.50717647, 0.5071726 , 0.50672383,\n",
       "        0.49542923, 0.50702991, 0.50717967, 0.50716576, 0.50717973,\n",
       "        0.50715148, 0.50696808, 0.50716622, 0.49445949, 0.49621245,\n",
       "        0.50698612, 0.50717129, 0.50717888, 0.49426829, 0.50714006,\n",
       "        0.5071577 , 0.50716076, 0.50627293, 0.50555098, 0.50711981,\n",
       "        0.50717002, 0.49977615, 0.50072707, 0.50705935, 0.5070979 ,\n",
       "        0.50702428, 0.50715237, 0.50715031, 0.49404932, 0.50715053,\n",
       "        0.50646755, 0.50712618, 0.50715581, 0.50660388, 0.50271241,\n",
       "        0.50716837, 0.49621689, 0.50712249, 0.4940371 , 0.50659946,\n",
       "        0.50708803, 0.50454733, 0.50717809, 0.50633311, 0.50717972,\n",
       "        0.50708201, 0.50717973, 0.49794923, 0.50713007, 0.5071265 ,\n",
       "        0.50696881, 0.50703482, 0.49501636, 0.50713206, 0.50717136,\n",
       "        0.5068175 , 0.5036055 , 0.50696483, 0.50717051, 0.50691403,\n",
       "        0.50717695, 0.4953811 , 0.50292354, 0.50104427, 0.49641882,\n",
       "        0.50108646, 0.50717973, 0.50623512, 0.49403544, 0.49403774,\n",
       "        0.49466342, 0.50663424, 0.50661776, 0.50693796, 0.50717793,\n",
       "        0.49423545, 0.50662942, 0.50235071, 0.50567764, 0.50717735,\n",
       "        0.50687743, 0.49686618, 0.50717839, 0.50472281, 0.50087884,\n",
       "        0.49772878, 0.49447539, 0.50642373, 0.4944488 , 0.49432993,\n",
       "        0.50414574, 0.49756508, 0.49889642, 0.49538531, 0.49451674,\n",
       "        0.49423222, 0.50191128, 0.49403968, 0.50626469, 0.50713654,\n",
       "        0.50717838, 0.49419369, 0.50717954, 0.50702687, 0.50348585,\n",
       "        0.50715458, 0.49426087, 0.50316403, 0.50254677, 0.49600505,\n",
       "        0.50712621, 0.50698891, 0.49737993, 0.4941534 , 0.49403491,\n",
       "        0.49403655, 0.49529586, 0.50703818, 0.49738603, 0.49470647,\n",
       "        0.50717943, 0.49403514, 0.49403495, 0.49432803, 0.5071771 ,\n",
       "        0.49410651, 0.49694372, 0.50715497, 0.49772334, 0.50566348,\n",
       "        0.49469469, 0.49656836, 0.49403537, 0.49403486, 0.49403493,\n",
       "        0.49450817, 0.49769975, 0.50683167, 0.50618236, 0.50367126,\n",
       "        0.49823733, 0.49406374, 0.49408759, 0.49403487, 0.50644446,\n",
       "        0.50654377, 0.49622074, 0.50623617, 0.49637092, 0.49418049,\n",
       "        0.4946948 , 0.49416912, 0.49870999, 0.50687151, 0.49404625,\n",
       "        0.49403487, 0.49567   , 0.49415541, 0.49404172, 0.50022071,\n",
       "        0.494117  , 0.49672481, 0.49406757, 0.49449816, 0.4948486 ,\n",
       "        0.49404329, 0.4942436 , 0.50255347, 0.49408132, 0.49438298,\n",
       "        0.49403663, 0.49412102, 0.50705343, 0.49433413, 0.49420483,\n",
       "        0.49404727, 0.4940379 , 0.49404148, 0.49403646, 0.49416241,\n",
       "        0.49409348, 0.49416999, 0.50716396, 0.49403486, 0.49404733,\n",
       "        0.49420412, 0.5010998 , 0.49403486, 0.49403621, 0.49430551,\n",
       "        0.49412741, 0.49415703, 0.49408587, 0.49403892, 0.49411382,\n",
       "        0.49466782, 0.49404775, 0.49403823, 0.49412944, 0.50665719,\n",
       "        0.49408556, 0.49406923, 0.50714205, 0.49407012, 0.49530307,\n",
       "        0.49404878, 0.49403614, 0.49403591, 0.49403485, 0.50313859,\n",
       "        0.4940695 , 0.49403485, 0.49705617, 0.49520602, 0.49406765,\n",
       "        0.49419936, 0.49403488, 0.49403767, 0.49509854, 0.49403523,\n",
       "        0.49403851, 0.49403757, 0.49450003, 0.4940747 , 0.49405157,\n",
       "        0.50638662, 0.49722132, 0.49404492, 0.49403485, 0.4940699 ,\n",
       "        0.50716024, 0.494038  , 0.49403488, 0.49403493, 0.49403662,\n",
       "        0.49404994, 0.49403941, 0.49403505, 0.4943553 , 0.49403515,\n",
       "        0.49403489, 0.49403485, 0.49405722, 0.4940352 , 0.49403513,\n",
       "        0.49403558, 0.49403504, 0.49403485, 0.49403542, 0.49403494,\n",
       "        0.49403775, 0.49403623, 0.49403489, 0.49403657, 0.49403614,\n",
       "        0.49403485, 0.49403486, 0.49403485, 0.49403535, 0.49403496,\n",
       "        0.49403486, 0.49403485, 0.49403493, 0.49403522, 0.49407605,\n",
       "        0.49403503, 0.49403489, 0.49756324, 0.49403485, 0.49403493,\n",
       "        0.49403488, 0.494035  , 0.49403539, 0.49403486, 0.49403489,\n",
       "        0.49403486, 0.50496101, 0.49403767, 0.49403512, 0.49403485,\n",
       "        0.49403509, 0.49406645, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403501, 0.49403486, 0.49403489, 0.49408534, 0.49404599,\n",
       "        0.49403485, 0.49403485, 0.49403489, 0.49403486, 0.49403557,\n",
       "        0.49403486, 0.49403857, 0.49403492, 0.49403485, 0.49404213,\n",
       "        0.49403486, 0.49403487, 0.49403485, 0.49403486, 0.49403489,\n",
       "        0.49403487, 0.49403485, 0.49403566, 0.49403491, 0.49403491,\n",
       "        0.49403515, 0.49403486, 0.49404171, 0.49403505, 0.49403488,\n",
       "        0.49403488, 0.49417265, 0.49403487, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403486, 0.49403486,\n",
       "        0.49403485, 0.49403485, 0.4940349 , 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403486, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403486, 0.49403541, 0.49403485, 0.49403485,\n",
       "        0.49403493, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49404027, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403506,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403485, 0.49403491,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403498,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403486, 0.49403485,\n",
       "        0.49403485, 0.49404992, 0.49403485, 0.49403496, 0.49403485,\n",
       "        0.49403487, 0.49403485, 0.49403486, 0.49403488, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403507, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403487, 0.49403856, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403495, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403488, 0.49403918, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403488, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403486, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403489, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485, 0.49403485, 0.49403485, 0.49403485, 0.49403485,\n",
       "        0.49403485]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension 11\n"
     ]
    }
   ],
   "source": [
    "def backward_propagation_NN(parameters, cache, X, Y):\n",
    "    \n",
    "    dimension = X.shape[0] # it is 20 for our case\n",
    "    print(\"dimension \"+str(dimension))\n",
    "    dZ3 = cache[\"A3\"] - Y # d(cost)/d(Z3)\n",
    "    dW3 = 1/dimension * np.dot(dZ3,cache[\"A2\"].T) # d(cost)/d(W3)\n",
    "    db3 = 1/dimension * np.sum(dZ3, axis=1) # d(cost)/d(b3)\n",
    "    dZ2 = np.multiply(np.dot(dZ3.T, cache[\"W3\"]).T , 1-np.power(cache[\"A2\"],2)) # d(cost)/d(Z2)\n",
    "    dW2 = 1/dimension * np.dot(cache[\"A1\"], dZ2.T) # d(cost)/d(W2)\n",
    "    db2 = 1/dimension * np.sum(dZ2, axis=1) # d(cost)/d(b2)\n",
    "    dZ1 = np.multiply(np.dot(dZ2.T, cache[\"W2\"].T).T,1-np.power(cache[\"A1\"],2)) # d(cost)/d(Z1)\n",
    "    dW1 = 1/dimension * np.dot(dZ1, X.T) # d(cost)/d(W1)\n",
    "    db1 = 1/dimension * np.sum(dZ1,axis=1) # d(cost)/d(b1)\n",
    "    grads = {'dW3':dW3, \n",
    "             'db3':db3,\n",
    "             'dW2':dW2,\n",
    "             'db2':db2,\n",
    "             'dW1':dW1,\n",
    "             'db1':db1}\n",
    "    \n",
    "    return grads\n",
    "\n",
    "grads = backward_propagation_NN(parameters, cache, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[\"b3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    9.104745\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[\"db3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW3': array([[-0.63743956,  0.74882357]]), 'db3': Survived    9.104745\n",
       " dtype: float64, 'dW2': array([[2.37027241, 0.90301299],\n",
       "        [1.14017181, 0.43291377]]), 'db2': array([2.3729473 , 0.90403043]), 'dW1': array([[-4.06727853e-03, -9.55942547e-04, -4.32039862e-04,\n",
       "         -3.42771670e-03, -8.18696534e-04, -1.34058659e-04,\n",
       "         -4.86895361e-03,  3.31632041e-05, -3.30258691e-05,\n",
       "         -2.98965620e-04,  4.02697865e-09],\n",
       "        [ 2.81141398e+00,  5.27177261e-02,  2.41742161e-02,\n",
       "          5.01017682e-01,  2.49088552e-02,  8.87601828e-03,\n",
       "          3.36465492e-01,  3.67826378e-04,  8.44406985e-04,\n",
       "          1.71495084e-02, -2.34885906e-06]]), 'db1': array([-0.00029882,  0.01835939])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-db8e72ab2667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mLearning_Rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"db3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_na_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m         return construct_result(left, result,\n\u001b[1;32m-> 1071\u001b[1;33m                                 index=left.index, name=res_name, dtype=None)\n\u001b[0m\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36m_construct_result\u001b[1;34m(left, result, index, name, dtype)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[1;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0menough\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mstill\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0moverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mattribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m     \"\"\"\n\u001b[1;32m--> 980\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[1;32m--> 275\u001b[1;33m                                        raise_cast_failure=True)\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m   4163\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data must be 1-dimensional'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4166\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_asarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "parameters[\"b3\"]-Learning_Rate*grads[\"db3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_NN(parameters, grads, learning_rate = Learning_Rate):\n",
    "    parameters = {\"W1\": parameters[\"W1\"]-learning_rate*grads[\"dW1\"],\n",
    "                  \"b1\": parameters[\"b1\"]-learning_rate*grads[\"db1\"],\n",
    "                  \"W2\": parameters[\"W2\"]-learning_rate*grads[\"dW2\"],\n",
    "                  \"b2\": parameters[\"b2\"]-learning_rate*grads[\"db2\"],\n",
    "                  \"W3\": parameters[\"W3\"]-learning_rate*grads[\"dW3\"],\n",
    "                  \"b3\": parameters[\"b3\"][0]-learning_rate*grads[\"db3\"]}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "parameters = update_parameters_NN(parameters, grads, learning_rate = Learning_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,11) and (8,418) not aligned: 11 (dim 1) != 8 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-53d2fe1f95b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mY_prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mY_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-53d2fe1f95b5>\u001b[0m in \u001b[0;36mpredict_NN\u001b[1;34m(parameters, x_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# x_test is the input for forward propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mY_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e99b797dda63>\u001b[0m in \u001b[0;36mforward_propagation_NN\u001b[1;34m(x_train, parameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# tanh is used as activation function 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,11) and (8,418) not aligned: 11 (dim 1) != 8 (dim 0)"
     ]
    }
   ],
   "source": [
    "def predict_NN(parameters,x_test):\n",
    "    # x_test is the input for forward propagation\n",
    "    A3, cache = forward_propagation_NN(x_test,parameters)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "\n",
    "    for i in range(A3.shape[1]):\n",
    "        if A3[0,i]<= 0.5: # if smaller than 0.5, predict it as 0\n",
    "            Y_prediction[0,i] = 0\n",
    "        else: # if greater than 0.5, predict it as 1\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "\n",
    "Y_prediction = predict_NN(parameters,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension 11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,891) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-dd3297cb55b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthree_layer_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-dd3297cb55b5>\u001b[0m in \u001b[0;36mthree_layer_neural_network\u001b[1;34m(x_train, y_train, x_test, y_test, num_iterations)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# forward propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# compute cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e99b797dda63>\u001b[0m in \u001b[0;36mforward_propagation_NN\u001b[1;34m(x_train, parameters)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mZ1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mA1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# tanh is used as activation function 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mZ2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"b2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,891) (2,2) "
     ]
    }
   ],
   "source": [
    "def three_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n",
    "    cost_list = []\n",
    "    index_list = []\n",
    "    \n",
    "    #initialize parameters and layer sizes\n",
    "    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        # forward propagation\n",
    "        A3, cache = forward_propagation_NN(x_train,parameters)\n",
    "        # compute cost\n",
    "        cost = compute_cost_NN(A3, y_train, parameters)\n",
    "        # backward propagation\n",
    "        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n",
    "        # update parameters\n",
    "        parameters = update_parameters_NN(parameters, grads)\n",
    "        \n",
    "        if i % 100 == 0: # to visualize data in each 100 iteration\n",
    "            cost_list.append(cost)\n",
    "            index_list.append(i)\n",
    "\n",
    "    figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(index_list,cost_list)\n",
    "    plt.xticks(index_list,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarions\", fontsize = 14)\n",
    "    plt.ylabel(\"Cost\", fontsize = 14)\n",
    "    plt.show()\n",
    "    \n",
    "    # predict\n",
    "    y_prediction_test = predict_NN(parameters,x_test)\n",
    "    y_prediction_train = predict_NN(parameters,x_train)\n",
    "\n",
    "    # Print train/test Accuracies\n",
    "    print(\"train accuracy: %{}\".format(round(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100,3)))\n",
    "    print(\"test accuracy: %{}\".format(round(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100,3)))\n",
    "    return parameters\n",
    "\n",
    "parameters = three_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
